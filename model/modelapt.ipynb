{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTING APPARTMENT PRICES IN BELGIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE='data_last.csv'\n",
    "df=pd.read_csv(FILE,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_na=[features for features in df.columns if df[features].isnull().sum()>1]\n",
    "\n",
    "for feature in features_with_na:\n",
    "    print(feature, np.round(df[feature].isnull().mean(), 4),  ' % missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoder, drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_ordinal=['G', 'F', 'E','D', 'C', 'B', 'A', 'A+', 'A++']\n",
    "building_condition_ordinal=['TO_BE_DONE_UP', 'JUST_RENOVATED', 'GOOD','AS_NEW']\n",
    "kitchen_type_ordinal=['INSTALLED','USA_INSTALLED', 'SEMI_EQUIPPED', 'USA_SEMI_EQUIPPED', 'HYPER_EQUIPPED',  'USA_HYPER_EQUIPPED']\n",
    "subtype_ordinal=['APARTMENT','DUPLEX','PENTHOUSE','TRIPLEX','LOFT']\n",
    "\n",
    "\n",
    "drop_cols=['transaction.sale.isSubjectToVat','id']\n",
    "num_cols=[\t'bedroomCount',\t'bathroomCount',\t'netHabitableSurface',\t'toiletCount']\n",
    "\n",
    "\n",
    "cat_cols=['subtype','transaction.certificates.epcScore',\t'building.condition',\t'kitchen.type']\n",
    "\n",
    "\n",
    "ord_col=['transaction.certificates.epcScore',\t'building.condition',\t'kitchen.type','subtype']\n",
    "\n",
    "\n",
    "dl=df.copy()\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder(categories=[epc_ordinal,building_condition_ordinal,kitchen_type_ordinal,subtype_ordinal])\n",
    "\n",
    "df[[\"transaction.certificates.epcScore\", \"building.condition\",'kitchen.type',\"subtype\"]] = enc.fit_transform(df[[\"transaction.certificates.epcScore\", \"building.condition\",\n",
    "                                                                                                                    'kitchen.type',\"subtype\"]])\n",
    "\n",
    "df = df.drop(drop_cols,axis=1)\n",
    "\n",
    "y=df['transaction.sale.price'].values\n",
    "X=df.drop(['transaction.sale.price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,10))\n",
    "sns.heatmap(df.corr())\n",
    "df.corr().style.background_gradient(cmap=\"Blues\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model \n",
    "Best model is choosen with pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "regr=CatBoostRegressor(nan_mode= 'Min', eval_metric= 'RMSE', iterations=1000, sampling_frequency= 'PerTree', leaf_estimation_method= 'Newton', grow_policy= 'SymmetricTree', \n",
    "                penalties_coefficient=1, boosting_type= 'Plain', model_shrink_mode= 'Constant', feature_border_type= 'GreedyLogSum', l2_leaf_reg=3, random_strength=1, rsm=1, \n",
    "                boost_from_average= True, model_size_reg=0.5, subsample=0.800000011920928, use_best_model= False, random_seed=10, depth=6, posterior_sampling= False, border_count=254, \n",
    "                 sparse_features_conflict_fraction=0, leaf_estimation_backtracking= 'AnyImprovement', best_model_min_trees=1, model_shrink_rate=0, min_data_in_leaf=1, \n",
    "                 loss_function= 'RMSE', learning_rate=0.0396099984645843, score_function= 'Cosine', task_type= 'CPU', leaf_estimation_iterations=1, bootstrap_type= 'MVS',\n",
    "                  max_leaves=64,verbose=False\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % regr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp=list(zip(X.columns,regr.feature_importances_))\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Export model to pkl file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(regr, \"clf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Some Useful Code and other tests applied to model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk=regr.predict(X)\n",
    "dl['predicted']=dk\n",
    "dl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kfold feature selection and other models tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "\n",
    "\n",
    "#regr = LinearRegression()\n",
    "#regr=KNeighborsRegressor()\n",
    "regr=GradientBoostingRegressor(n_estimators=400,max_depth=2,min_samples_split=2,learning_rate=0.1) \n",
    "\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "hp_candidates = [{'n_estimators': [200,300,400,500,1000], 'max_depth': [2,3,4,5,16]}]\n",
    "\n",
    "# Search for best hyperparameters\n",
    "grid = GridSearchCV(estimator=regr, param_grid=hp_candidates, cv=kfold, scoring='r2')\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en = ElasticNet(alpha = 0.01)\n",
    "en.fit(X_train, y_train)\n",
    "en.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "bayesian = BayesianRidge()\n",
    "bayesian.fit(X_train, y_train)\n",
    "bayesian.score(X_test, y_test)\n",
    "bayesian.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train, y_train)\n",
    "ols.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(max_iter=5000, alpha = 0.01)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso.score(X_test, y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
